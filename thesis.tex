 \documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage{amsthm}
\usepackage{amsmath, amssymb, amsfonts}
\usepackage{mathrsfs}
\usepackage{titling}
\usepackage{hyperref}
\usepackage{url}
\usepackage{bbm}
\usepackage{xcolor}
\usepackage{graphicx}
\graphicspath{ {./Slike/} }
\usepackage{subcaption}

\usepackage{geometry}
\geometry{
 a4paper,
 %total={170mm,257mm},
 left=30mm,
 right=30mm,
 top=20mm,
 bottom=20mm
}

\newcommand{\A}{\mathcal{A}}
\newcommand{\D}{\mathcal{D}}
\renewcommand{\d}{\mathrm{d}}
\newcommand{\G}{\mathcal{G}}
\renewcommand{\H}{\mathcal{H}}
\newcommand{\Loc}{\mathcal{L}}
\renewcommand{\L}{\mathbb{L}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\N}{\mathbb{N}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\PP}{\mathsf{P}}
\newcommand{\R}{\mathbb{R}}
\renewcommand{\r}{\mathrm{r}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\ZZ}{\mathcal{Z}}

\newcommand{\BM}{\mathrm{BM}}
\newcommand{\Potts}{\mathrm{Potts}}
\newcommand{\TV}{\mathrm{TV}}

\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\oklepaj}[1]{\left(#1\right)}
\newcommand{\oglati}[1]{\left[#1\right]}
\newcommand{\ra}{\rightarrow}
\newcommand{\pika}{\boldsymbol{\cdot}}
\newcommand{\1}{\mathbbm{1}}
\renewcommand{\sp}[1]{\langle #1\rangle}
\newcommand{\ind}{\perp\!\!\!\!\perp}
\renewcommand{\c}{\mathsf{c}}
\newcommand{\supp}{\mathrm{supp}}
\newcommand{\5}{\vspace{0.5cm}}

\theoremstyle{definition}
\newtheorem{thm}{Theorem}[section]
\newtheorem{ex}[thm]{Example}
\newtheorem{prop}[thm]{Proposition}
\newtheorem*{sol}{Solution}
\newtheorem*{dis}{Disclaimer}
\newtheorem{df}[thm]{Definition}
\newtheorem{rem}[thm]{Remark}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}

\setlength{\droptitle}{-2cm}
\title{\textsc{Random Polymers Near a Homogeneous Interface}\\\vspace{0.3cm}\small{Statistical Mechanics}\vspace{-0.7cm}}
\author{Oskar Vavtar}
\date{\today}

\begin{document}
\begin{center}
\Huge{\textcolor{teal}{\texttt{TITLE}}} \\
\vspace{2cm}
\Huge{\textcolor{teal}{\texttt{TITLE}}} \\
\vspace{2cm}
Leiden University \\
\vspace{2cm}
{\textsc{Absence of Phase Transitions and Preservation of Gibbs Property under Renormalization}} \\
\vspace{2cm}
Oskar Vavtar \\
\vspace{2cm}
\Huge{\textcolor{teal}{\texttt{TITLE}}} \\
\vspace{2cm}
\Huge{\textcolor{teal}{\texttt{TITLE}}} \\
\vspace{2cm}
\Huge{\textcolor{teal}{\texttt{TITLE}}}
\end{center}
\pagebreak
\tableofcontents
\pagebreak

% #################################################################################################
% #################################################################################################
% #################################################################################################

\section{Introduction (probably better name)}

\textcolor{blue}{I assume this chapter will include a brief introduction to Gibbs measures/thermodynamical formalism (possibly including definitions of Ising and Potts model), as well as the theory of fuzzy Gibbs measures, results from Berghout's thesis.} 

\pagebreak

% #################################################################################################
% #################################################################################################
% #################################################################################################

\section{(Non-)Gibbsianity of fuzzy Potts model}

This chapter aims to introduce the fuzzy Potts model and provide an alternative, independent proof of H\"aggstr\"om's theorem \textcolor{red}{\texttt{[reference]}} about its (non-)Gibbsianity, using the results due to Berghout and Verbitskiy \textcolor{red}{\texttt{[reference]}}. Moreover, it introduces the notion of random cluster representations, a powerful tool in the theory of Potts model, which is used in the proof.

% #################################################################################################

\subsection{Fuzzy Potts model}

In this introductory section of the chapter, we define the fuzzy Potts model and state the celebrated result about its (non-)Gibbsianity, due to H\"aggstr\"om \textcolor{red}{\texttt{[reference]}}. Moreover, we explain the strategy and structure of our alternative proof of (part of) the said result. \\

Consider the Potts model with spin space $\set{1,\ldots,q}$, $q\geq 2$, on lattice $\L$, say $\L=\Z^d$, which defines a model on $\Omega=\set{1,\ldots,q}^\L$. The \textit{fuzzy Potts model} is defined by considering some integer $1<s<q$, so that the spin space is $\set{1,\ldots,s}$ and the whole model defined on $\Sigma=\set{1,\ldots,s}^\L$. Moreover, we consider a vector $\r=(r_1,\ldots,r_s)\in\N^s$, such that $r_1+\ldots+r_s=q$ and define a fuzzy transformation $\pi_\r:\set{1,\ldots,q}\ra\set{1,\ldots,s}$ by putting 
$$\pi_\r(a) ~:=~ \begin{cases}
1: ~&1\leq a\leq r_1,\\
2: ~&r_1+1\leq a\leq r_1+r_2 \\
\cdots \\
n: ~&\sum_{i=1}^{n-1} r_i + 1\leq a\leq \sum_{i=1}^n r_i,\\
\cdots \\
s: ~&\sum_{i=1}^{s-1}r_i + 1\leq a\leq q,
\end{cases}$$
i.e., $\pi_a=n$ iff $a\in(\sum_{i=1}^{n-1}r_i,\sum_{i=1}^n r_i]\cap \N$, $n\in\set{1,\ldots,s}$. In other words, the entire fuzzy map $\pi=\pi_\r$ is encoded by a single $s$-vector $\r$. \\

Fixing $q\geq 2$, $\beta\geq 0$ and writing $\mu_{q,\beta}^{\Z^d,\#}$ for the Gibbs measure of the Potts model on $\set{1,\ldots,q}^{\Z^d}$ for boundary condition $\#\in\set{0,\ldots,q}$ with inverse temperature $\beta$, the fuzzy transformation $\pi_\r$ induces the fuzzy Gibbs measure 
$$\nu_{q,\beta,\r}^{\Z^d,\#} ~:=~ \mu_{q,\beta}^{\Z^d,\#}\circ\pi_\r^{-1}.$$
Of great interest is the potential Gibbsianity of such measure. \textcolor{blue}{\texttt{Something about the H\"aggstr\"om's result blahblahblah.}} Recall that for \textcolor{purple}{$q\geq 2$ and $d\geq 2$}, there exists $\beta_c(d,q)\in(0,\infty)$ such that for each $\beta<\beta_c(d,q)$, $\mu_{q,\beta}^{\Z^d,0}=\ldots=\mu_{q,\beta}^{\Z^d,q}$, i.e., there is a unique Gibbs measure of the Potts model on $\set{1,\ldots,q}^{\Z^d}$ with inverse temperature $\beta$, while for each $\beta>\beta_c(d,q)$ there are $q$ mutually singular Gibbs measures \textcolor{purple}{\texttt{[q+1?]}}.

\begin{thm}[H\"aggstr\"om, 2003, \textcolor{red}{\texttt{[reference]}}]
Let $d\geq 2$, $q\geq 3$, $\#\in\set{0,\ldots,q}$ and $\r=(r_1,\ldots,r_s)$ with $1<s<q$, $r_1+\ldots+r_s=q$, and write $r^*=\min_{1\leq i\leq s}r_i$. Consider a fuzzy Gibbs measure $\nu_{q,\beta,\r}^{\Z^d,\#}=\mu_{q,\beta}^{\Z^d,\#}\circ\pi_{\r}^{-1}$.
\begin{itemize}
	\item[(i)] For each $\beta<\beta_c(d,r^*)$, the measure $\nu_{q,\beta,\r}^{\Z^d,\#}$ is a Gibbs measure.
	\item[(ii)] \textcolor{blue}{\texttt{The non-Gibbs part.}}
\end{itemize}
\end{thm}

\begin{rem}
\textcolor{blue}{\texttt{Remark about the ordering of $\beta_c(d,r_1),\ldots,\beta_c(d,r_s)$, given the ordering of $r_1,\ldots,r_s$. Explain that this condition gives uniqueness of Gibbs measure on each $\set{1,\ldots,r_i}^{\Z^d}$.}}
\end{rem}

In light of the theory from the previous chapter, we are particularly interested in part (i) of the theorem, the Gibbs regime. The van Enter-Fern\'andez-Sokal hypothesis, would suggest that, since for $\beta<\beta_c(d,r^*)$ the Gibbs property is preserved, \textcolor{purple}{each $\mu_{q,\beta}^{\Z^d,\#}$ should admit a continuous disintegration in terms of $\nu_{q,\beta,\r}^{\Z^d,\#}$}. Moreover, proving the latter would -- applying the result of \textcolor{red}{\texttt{[theorem reference]}} -- constitute an alternative and independent proof of \textcolor{red}{\texttt{[Theorem 2.1]}}.(i). \\

Given \textcolor{red}{\texttt{Theorem reference}}, it is sufficient to verify (for a fixed $\beta<\beta_c(d,r^*))$, that for each $\sigma\in\Sigma=\set{1,\ldots,s}^{\Z^d}$, there is a unique Gibbs measure for $q$-Potts model with inverse temperature beta on the fibre $\Omega_\sigma=\pi_\r^{-1}(\sigma)$, i.e., that
$$|\G_{\Omega_\sigma}(\Phi_{q,\beta}^\Potts)| ~=~ 1, \quad \forall \sigma\in\Sigma.$$
Luckily, one can express the fibres in a rather nice way, allowing for an easier procedure. Given $\sigma\in\Sigma$, we simply have
$$\Omega_\sigma ~=~ \pi_{\r}^{-1} ~=~ \prod_{i\in\Z^d}\pi_{\r}^{-1}(\sigma_i).$$
Writing $\A_j:=\pi_{\r}^{-1}(j)$ and $U_j:=\set{i\in\Z^d:\pi_{\r}(\sigma_i)=j}$, $j=1,\ldots,s$, we could also write
$$\Omega_\sigma ~=~ \textcolor{purple}{\bigotimes_{j=1}^s\A_j^{U_j}} ~:=~ \prod_{i\in\Z^d}\begin{cases}\A_1:~&i\in U_1,\\
\cdots\\
\A_s:~&i\in U_s.\end{cases}$$
One way of proving the uniqueness of $q$-Potts Gibbs measure on such $\Omega_\sigma$ for \textcolor{blue}{\texttt{an appropriate}} inverse temperature $\beta$, is via the following two steps (so far stated informally):
\begin{itemize}
	\item[(1)] Given the assumption on $\beta$, we know that for each $j=1,\ldots,s$, there is a unique Gibbs measure for Potts model on $\A_j^{\Z^d}$ with inverse temperature $\beta$. We wish to show that this implies also uniqueness of Gibbs measure for Potts model on $\A_j^{U_j}$, given the same inverse temperature.
	\item[(2)] Given the uniqueness of Gibbs measure for Potts model on $\A_j^{U_j}$ with inverse temperature $\beta$ for all $j=1,\ldots,s$, we need to show that this implies the uniqueness of Gibbs measure for Potts model on $\bigotimes_{j=1}^s \A_j^{U_j}$, given the same inverse temperature.
\end{itemize}
\textcolor{blue}{\texttt{Here, I will remark that it is enough to check this for $s=2$, and proceed to restate the above points more formally, in terms of two propositions.}}

% #################################################################################################

\subsection{Preliminaries, part 1: stochastic domination}

In this and the next section, we will introduce some tools, which will be used to prove \textcolor{red}{\texttt{[Proposition reference]}}. The section will cover the basics on stochastic domination, a well-established tool in mathematical statistical mechanics. In the section that follows, we introduce the theory of random cluster representations, which are important in study of the Potts model in particular. 


Assume firstly that $\A\subset\R$ is linearly ordered; in our case, we are generally assuming $\A$ to be finite, though this theory can be extended to closed subsets of $\R$. Then linear order of $\A$ induces a natural (coordinatewise) partial order on $\Omega=\A^\L$: given two configurations $\xi,\xi'\in\Omega$, we write
$$\xi\preceq\xi' ~\iff~ \xi(i)\leq\xi'(i),~\forall i\in\L.$$
This allows us to introduce a notion of increasing functions:

\begin{df}[Increasing functions and events]
~
\begin{itemize}
	\item[(1)] We say that a function $f:\Omega\ra\R$ is \textit{increasing} (or \textit{non-decreasing}), if for each $\xi,\xi'\in\Omega$, $\xi\preceq\xi'$ implies $f(\xi)\leq f(\xi')$. 
	\item[(2)] Equipped with the previous notion, we say that an event $A$ (or a simply $A\subset\Omega$ measurable) is \textit{increasing} if $\1_A$ is an increasing function.
\end{itemize}
\end{df}

\begin{ex}
\textcolor{blue}{\texttt{Percolation probability.}}
\end{ex}

 This allows us to define a certain partial order on $\M_1(\Omega)$, the set of probability measures on $\Omega$. \textcolor{blue}{\texttt{Some comment about motivation for defining stochastic domination/ordering on measures?}}
 
\begin{df}[Stochastic domination]
Let $\mu$ and $\mu'$ be probability measures on $\Omega$. We say that $\mu$ is \textit{stochastically dominated} by $\mu'$, writing $\mu\preceq_\D\mu'$, if
$$\int f\,\d\mu ~\leq~ \int f\,\d\mu', \quad \forall f\in\BM(\Omega,\R).$$
\end{df}

\textcolor{blue}{\texttt{Somethingsomething coupling}}

\begin{df}[Coupling]
Given two probability measures $\mu,\mu'$ on $\Omega$, their \textit{coupling} is defined to be a probability measure $\PP$ on $\Omega\times\Omega$, such that its marginals agree with $\mu$ and $\mu'$, that is
$$\PP(\set{(\xi,\xi'):\xi\in A}) ~=~ \mu(A) \quad \text{and} \quad \PP(\set{(\xi,\xi'):\xi'\in B}) ~=~ \mu'(B).$$
\end{df}

\textcolor{blue}{\texttt{The rest of this section will depend on which argument exactly I will use in the proof, but both Strassen and Holley could be introduced, as a part of a ``general introduction''.}}

% #################################################################################################

\subsection{Preliminaries, part 2: random cluster representations}

% #################################################################################################
% #################################################################################################
% #################################################################################################

\end{document}