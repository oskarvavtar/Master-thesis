\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage{amsthm}
\usepackage{amsmath, amssymb, amsfonts}
\usepackage{mathrsfs}
\usepackage{titling}
\usepackage{hyperref}
\usepackage{url}
\usepackage{bbm}
\usepackage{xcolor}
\usepackage{graphicx}
\graphicspath{ {./Slike/} }
\usepackage{subcaption}

\usepackage{geometry}
\geometry{
 a4paper,
 %total={170mm,257mm},
 left=30mm,
 right=30mm,
 top=20mm,
 bottom=20mm
}

\newcommand{\A}{\mathcal{A}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\BB}{\mathscr{B}}
\newcommand{\D}{\mathcal{D}}
\renewcommand{\d}{\mathrm{d}}
\newcommand{\G}{\mathcal{G}}
\renewcommand{\H}{\mathcal{H}}
\newcommand{\Loc}{\mathcal{L}}
\renewcommand{\L}{\mathbb{L}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\N}{\mathbb{N}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\PP}{\mathsf{P}}
\newcommand{\R}{\mathbb{R}}
\renewcommand{\r}{\mathrm{r}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\ZZ}{\mathcal{Z}}

\newcommand{\BM}{\mathrm{BM}}
\newcommand{\Law}{\mathrm{Law}}
\newcommand{\Potts}{\mathrm{Potts}}
\newcommand{\TV}{\mathrm{TV}}

\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\oklepaj}[1]{\left(#1\right)}
\newcommand{\oglati}[1]{\left[#1\right]}
\newcommand{\ra}{\rightarrow}
\newcommand{\pika}{\boldsymbol{\cdot}}
\newcommand{\1}{\mathbbm{1}}
\renewcommand{\sp}[1]{\langle #1\rangle}
\newcommand{\ind}{\perp\!\!\!\!\perp}
\renewcommand{\c}{\mathsf{c}}
\newcommand{\supp}{\mathrm{supp}}
\newcommand{\5}{\vspace{0.5cm}}
\renewcommand{\tilde}{\widetilde}
\renewcommand{\hat}{\widehat}

\theoremstyle{definition}
\newtheorem{thm}{Theorem}[section]
\newtheorem{ex}[thm]{Example}
\newtheorem{prop}[thm]{Proposition}
\newtheorem*{sol}{Solution}
\newtheorem*{dis}{Disclaimer}
\newtheorem{df}[thm]{Definition}
\newtheorem{rem}[thm]{Remark}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}

\setlength{\droptitle}{-2cm}
\title{\textsc{Random Polymers Near a Homogeneous Interface}\\\vspace{0.3cm}\small{Statistical Mechanics}\vspace{-0.7cm}}
\author{Oskar Vavtar}
\date{\today}

\begin{document}
\begin{center}
\Huge{\textcolor{teal}{\texttt{TITLE}}} \\
\vspace{2cm}
\Huge{\textcolor{teal}{\texttt{TITLE}}} \\
\vspace{2cm}
Leiden University \\
\vspace{2cm}
{\textsc{Absence of Phase Transitions and Preservation of Gibbs Property under Renormalization}} \\
\vspace{2cm}
Oskar Vavtar \\
\vspace{2cm}
\Huge{\textcolor{teal}{\texttt{TITLE}}} \\
\vspace{2cm}
\Huge{\textcolor{teal}{\texttt{TITLE}}} \\
\vspace{2cm}
\Huge{\textcolor{teal}{\texttt{TITLE}}}
\end{center}
\pagebreak
\tableofcontents
\pagebreak

% #################################################################################################
% #################################################################################################
% #################################################################################################

\section{Introduction (probably better name)}

\textcolor{blue}{I assume this chapter will include a brief introduction to Gibbs measures/thermodynamical formalism (possibly including definitions of Ising and Potts model), as well as the theory of fuzzy Gibbs measures, results from Berghout's thesis.}\\ 

\textcolor{teal}{Could also be split into two chapters, first covering SM basics+examples and the second one stuff from Berghout's thesis.}

\pagebreak

% #################################################################################################
% #################################################################################################
% #################################################################################################

\section{(Non-)Gibbsianity of fuzzy Potts model}

This chapter aims to introduce the fuzzy Potts model and provide an alternative, independent proof of H\"aggstr\"om's result \textcolor{red}{\texttt{[reference]}} about conditions for its Gibbsianity, using the results due to Berghout and Verbitskiy \textcolor{red}{\texttt{[reference]}}. Moreover, it introduces the notion of random cluster representations, a powerful tool in the theory of Potts model, which is used in the proof.

% #################################################################################################

\subsection{Classical Potts model}

In this introductory section of the chapter, we define the classical Potts model, with respect to which the fuzzy Potts model will be later defined. We also state the celebrated result the existence of phase transition with respect to the inverse temperature parameter. \\

The Potts model is a natural generalization of (ferromagnetic) Ising model with zero external field ($h=0$), where instead of two possible values ($+/-$ or $1/-1$ in the context of the Ising model), the spins may assume $q\geq 2$ different values, taking $\set{1,\ldots,q}$ to be the state \textcolor{blue}{(spin)} space, and consequently $\Omega=\set{1,\ldots,q}^{\Z^d}$ to be the configuration space. As in the case of the Ising model, the interaction $\Phi$ is defined for $\textcolor{blue}{A}=\set{x,y}$, with $x\sim y$ (i.e., $|x-y|=1$) and is given by
$$\Phi(\omega_x,\omega_y) ~=~ 2\1_{\set{\omega_x\neq \omega_y}}-1 ~=~ \begin{cases}
1: ~&\omega_x\neq\omega_y, \\
-1: ~&\omega_x=\omega_y.
\end{cases}$$
Clearly, taking $q=2$ and identifying $\set{0,1}$ with $\set{-,+}$, one obtains the zero external field Ising model. The above interaction yields the following finite volume Hamiltonian expression: given $\Lambda\Subset\Z^d$, $\omega_\Lambda\in\Omega_\Lambda$ and $\sigma_{\Lambda^\c}\in\Omega_{\Lambda^\c}$, we have
$$\H_\Lambda(\omega_\Lambda\sigma_{\Lambda^\c}) ~=~ \beta\sum_{(x,y)\in\tilde{\Lambda}}(2\1_{\set{\omega_x\neq\omega_y}}-1)+\beta\sum_{(x,y)\in\partial\tilde{\Lambda}}(2\1_{\set{\omega_x\neq\sigma_y}}-1),$$
where $\tilde{\Lambda}:=\set{(x,y):x\sim y,\,x,y\in\Lambda}$ and $\partial\tilde{\Lambda}:=\set{(x,y):x\sim y,\,x\in\Lambda,y\in\Lambda^\c}$. We might, however, take a simpler equivalent interaction, which we justify shortly, in a remark. In the spirit of thermodynamical formalism, the system of Hamiltonians $(\H_\Lambda)_{\Lambda\Subset\Z^d}$ yields admits a specification $\gamma=(\gamma_\Lambda)_{\Lambda\Subset\Z^d}$, where for each $\Lambda\Subset\Z^d$ we have
\begin{align*}
\gamma_\Lambda:\BB(\Omega_\Lambda)\times\Omega_{\Lambda^\c}&\ra (0,1) \\
(\set{\omega_{\Lambda}},\sigma_{\Lambda^\c})&\mapsto\gamma_{\Lambda}(\omega_{\Lambda}|\sigma_{\Lambda^\c})=\frac{1}{\ZZ}\exp\!\oklepaj{-\H_\Lambda(\omega_\Lambda\sigma_{\Lambda^\c})},
\end{align*}
where $\ZZ_\Lambda=\sum_{\tilde{\omega}_\Lambda\in\Omega_\Lambda}\exp\!\oklepaj{-\H_\Lambda(\tilde{\omega}_{\Lambda}\sigma_{\Lambda^\c})}$.

\begin{rem}
\begin{itemize}
	\item[(1)] Both $\H_\Lambda$ and $\ZZ_\Lambda$, depend not only on $\Lambda$ but also on $q$ and $\beta$.
	\item[(2)] Notice that $$\H_{\Lambda}(\omega_{\Lambda}\sigma_{\Lambda^\c})=2\beta\sum_{(x,y)\in\tilde{\Lambda}}\1_{\set{\omega_x\neq\omega_y}} + 2\beta\sum_{(x,y)\in\partial\tilde{\Lambda}}\1_{\set{\omega_x\neq\sigma_y}}-\beta(|\tilde{\Lambda}|+|\partial\tilde{\Lambda}|),$$
	where $C_{\beta,\Lambda}:=\beta(|\tilde{\Lambda}|+|\partial\tilde{\Lambda}|)$ is a  constant independent of $\omega_{\Lambda},\sigma_{\Lambda^\c}$, giving us
	\begin{align*}
	\gamma_{\Lambda}(\omega_{\Lambda}|\sigma_{\Lambda^\c}) ~&=~ \frac{\exp(-\H_{\Lambda}(\omega_{\Lambda}\sigma_{\Lambda^\c}))}{\sum_{\tilde{\omega}_{\Lambda}\in\Omega_{\Lambda}}\exp(-\H_{\Lambda}(\tilde{\omega}_{\Lambda}\sigma_{\Lambda^\c}))} \\
	&=~ \frac{\exp\!\oklepaj{-2\beta\!\oglati{\sum_{(x,y)\in\tilde{\Lambda}}\1_{\set{\omega_x\neq\omega_y}} + \sum_{(x,y)\in\partial\tilde{\Lambda}}\1_{\set{\omega_x\neq\sigma_y}}}}\exp(C_{\beta,\Lambda})}{\exp(C_{\beta,\Lambda})\sum_{\tilde{\omega}_{\Lambda}\in\Omega_{\Lambda}}\exp\!\oklepaj{-2\beta\!\oglati{\sum_{(x,y)\in\tilde{\Lambda}}\1_{\set{\tilde{\omega}_x\neq\tilde{\omega}_y}} + \sum_{(x,y)\in\partial\tilde{\Lambda}}\1_{\set{\tilde{\omega}_x\neq\sigma_y}}}}} \\
	&=~ \frac{\exp\!\oklepaj{-2\beta\!\oglati{\sum_{(x,y)\in\tilde{\Lambda}}\1_{\set{\omega_x\neq\omega_y}} + \sum_{(x,y)\in\partial\tilde{\Lambda}}\1_{\set{\omega_x\neq\sigma_y}}}}}{\sum_{\tilde{\omega}_{\Lambda}\in\Omega_{\Lambda}}\exp\!\oklepaj{-2\beta\!\oglati{\sum_{(x,y)\in\tilde{\Lambda}}\1_{\set{\tilde{\omega}_x\neq\tilde{\omega}_y}} + \sum_{(x,y)\in\partial\tilde{\Lambda}}\1_{\set{\tilde{\omega}_x\neq\sigma_y}}}}},
	\end{align*}
	so the same specification would be obtained by selecting an alternative interaction and system of (finite volume) Hamiltonians
	\begin{align*}
	\Phi'(\omega_x,\omega_y) ~&=~ 2\1_{\set{\omega_x\neq\omega_y}}, \\
	\H_{\Lambda}'(\omega_{\Lambda}\sigma_{\Lambda^\c}) ~&=~ 2\beta\sum_{(x,y)\in\tilde{\Lambda}}\1_{\set{\omega_x\neq\omega_y}}+2\beta\sum_{(x,y)\in\partial\tilde{\Lambda}}\1_{\set{\omega_x\neq\sigma_y}}.
	\end{align*}
	For the sake of simplicity, from now on, we use will use $\Phi'$ and $(\H_\Lambda')_{\Lambda\Subset\Z^d}$ in our computations instead, and simply denote them by $\Phi$ and $(\H_{\Lambda})_{\Lambda\Subset\Z^d}$.
	\item[(3)] The interaction we initially used, is often also written in the literature as 
	$$\Phi(\omega_x,\omega_y) ~=~ 1-2\1_{\set{\omega_x=\omega_y}}.$$
	Had we used this version, we would in point (2) obtain $\Phi'(\omega_x,\omega_y)=-2\1_{\set{\omega_x=\omega_y}}$ instead.
	\item[(4)] There are several other interactions that equivalently define the Potts model. \textcolor{blue}{Give examples.} \textcolor{blue}{$\1_{\set{\omega_x\neq\omega_y}}$ and $-\1_{\set{\omega_x=\omega_y}}$?}
\end{itemize}
\end{rem}

In the spirit of thermodynamical formalism, the (infinite volume) Gibbs measure for $q$-state Potts model on $\Omega$ with inverse temperature $\beta$ is any probability measure on $\Omega$, whose finite-volume conditional probabilities agree with the specification $\gamma$, that is, a measure $\mu\in\M_1(\Omega)$ such that for each $\Lambda\Subset\Z^d$ and $\omega$, one has
$$\mu(\omega~\text{on}~\Lambda|\sigma~\text{off}~\Lambda) ~=~ \gamma_\Lambda(\omega_\Lambda|\sigma_{\Lambda^\c}),$$
for $\mu$-a.e.~$\sigma\in\Omega$.

\begin{rem}
Notice that for any fixed $\sigma_{\Lambda^\c}\in\Omega_{\Lambda^\c}$, the map $\gamma_\Lambda(\pika|\sigma_{\Lambda^\c})$ is a probability measure on $\Omega_\Lambda$, which we can denote as $\mu_\Lambda^\sigma=\mu_{q,\beta,\Lambda}^\sigma$. We can, in this case, restate $\mu\in\M_1(\Omega)$ to be Gibbs measure for $q$-state Potts model with inverse temperature $\beta$ if for each $\Lambda\Subset\Z^d$ and $\mu$-a.e.~$\sigma\in\Omega$, 
$$\mu(\pika~\text{on}~\Lambda|\sigma~\text{off}~\Lambda) ~=~ \mu_{q,\beta,\Lambda}^\sigma.$$
\end{rem}

The Potts model enjoys \textcolor{blue}{a similar} phase transition result as the Ising model, as is stated in the following theorem.

\begin{thm}[\textcolor{blue}{By whom?ACCN?}]
For $q$-state Potts model on $\Z^d$ with $d\geq 2$, there exists a critical inverse temprature $\beta_c=\beta_c(d,q)\in(0,\infty)$ such that
\begin{itemize}
	\item[(i)] for each $\beta<\beta_c$ there is a unique Gibbs measure, and 
	\item[(ii)] for each $\beta>\beta_c$, there exist $q$ mutually singular Gibbs measures.
\end{itemize}
\end{thm}

It is worth mentioning that the mutually singular Gibbs measures in the $\beta>\beta_c$ regime are precisely the measures $\mu_{q,\beta}^1,\ldots,\mu_{q,\beta}^q$, where for $i\in\set{1,\ldots,q}$, $\mu_{q,\beta}^i$ is the thermodynamical limit
$$\mu_{q,\beta}^i ~=~ \lim_{\Lambda\Uparrow\Z^d}\mu_{q,\beta,\Lambda}^{\mathsf{i}},$$
where $\mathsf{i}=\set{i}^{\Z^d}$ is the constant boundary condition.

% #################################################################################################

\subsection{Fuzzy Potts model}

\textcolor{blue}{In this introductory section of the chapter, we define the fuzzy Potts model and state the celebrated result about its (non-)Gibbsianity, due to H\"aggstr\"om \textcolor{red}{\texttt{[reference]}}. Moreover, we explain the strategy and structure of our alternative proof of (part of) the said result.} \\

Consider the Potts model with spin space $\set{1,\ldots,q}$, $q\geq 2$, on lattice $\L$, say $\L=\Z^d$, which defines a model on $\Omega=\set{1,\ldots,q}^\L$. The \textit{fuzzy Potts model} is defined by considering some integer $1<s<q$, so that the spin space is $\set{1,\ldots,s}$ and the whole model defined on $\Sigma=\set{1,\ldots,s}^\L$. Moreover, we consider a vector $\r=(r_1,\ldots,r_s)\in\N^s$, such that $r_1+\ldots+r_s=q$ and define a fuzzy transformation $\pi_\r:\set{1,\ldots,q}\ra\set{1,\ldots,s}$ by putting 
$$\pi_\r(a) ~:=~ \begin{cases}
1: ~&1\leq a\leq r_1,\\
2: ~&r_1+1\leq a\leq r_1+r_2 \\
\cdots \\
n: ~&\sum_{i=1}^{n-1} r_i + 1\leq a\leq \sum_{i=1}^n r_i,\\
\cdots \\
s: ~&\sum_{i=1}^{s-1}r_i + 1\leq a\leq q,
\end{cases}$$
i.e., $\pi_a=n$ iff $a\in(\sum_{i=1}^{n-1}r_i,\sum_{i=1}^n r_i]\cap \N$, $n\in\set{1,\ldots,s}$. In other words, the entire fuzzy map $\pi=\pi_\r$ is encoded by a single $s$-vector $\r$. \\

Fixing $q\geq 2$, $\beta\geq 0$ and writing $\mu_{q,\beta}^{\Z^d,\#}$ for the Gibbs measure of the Potts model on $\set{1,\ldots,q}^{\Z^d}$ for boundary condition $\#\in\set{0,\ldots,q}$ with inverse temperature $\beta$, the fuzzy transformation $\pi_\r$ induces the fuzzy Gibbs measure 
$$\nu_{q,\beta,\r}^{\Z^d,\#} ~:=~ \mu_{q,\beta}^{\Z^d,\#}\circ\pi_\r^{-1}.$$
Of great interest is the potential Gibbsianity of such measure. \textcolor{blue}{\texttt{Something about the H\"aggstr\"om's result blahblahblah.}} Recall that for \textcolor{purple}{$q\geq 2$ and $d\geq 2$}, there exists $\beta_c(d,q)\in(0,\infty)$ such that for each $\beta<\beta_c(d,q)$, $\mu_{q,\beta}^{\Z^d,0}=\ldots=\mu_{q,\beta}^{\Z^d,q}$, i.e., there is a unique Gibbs measure of the Potts model on $\set{1,\ldots,q}^{\Z^d}$ with inverse temperature $\beta$, while for each $\beta>\beta_c(d,q)$ there are $q$ mutually singular Gibbs measures \textcolor{purple}{\texttt{[q+1?]}}.

\begin{thm}[H\"aggstr\"om, 2003, \textcolor{red}{\texttt{[reference]}}]
Let $d\geq 2$, $q\geq 3$, $\#\in\set{0,\ldots,q}$ and $\r=(r_1,\ldots,r_s)$ with $1<s<q$, $r_1+\ldots+r_s=q$, and write $r^*=\min_{1\leq i\leq s}r_i$. Consider a fuzzy Gibbs measure $\nu_{q,\beta,\r}^{\Z^d,\#}=\mu_{q,\beta}^{\Z^d,\#}\circ\pi_{\r}^{-1}$.
\begin{itemize}
	\item[(i)] For each $\beta<\beta_c(d,r^*)$, the measure $\nu_{q,\beta,\r}^{\Z^d,\#}$ is a Gibbs measure.
	\item[(ii)] \textcolor{blue}{\texttt{The non-Gibbs part.}}
\end{itemize}
\end{thm}

\begin{rem}
\textcolor{blue}{\texttt{Remark about the ordering of $\beta_c(d,r_1),\ldots,\beta_c(d,r_s)$, given the ordering of $r_1,\ldots,r_s$. Explain that this condition gives uniqueness of Gibbs measure on each $\set{1,\ldots,r_i}^{\Z^d}$.}}
\end{rem}

In light of the theory from the previous chapter, we are particularly interested in part (i) of the theorem, the Gibbs regime. The van Enter-Fern\'andez-Sokal hypothesis, would suggest that, since for $\beta<\beta_c(d,r^*)$ the Gibbs property is preserved, \textcolor{purple}{each $\mu_{q,\beta}^{\Z^d,\#}$ should admit a continuous disintegration in terms of $\nu_{q,\beta,\r}^{\Z^d,\#}$}. Moreover, proving the latter would -- applying the result of \textcolor{red}{\texttt{[theorem reference]}} -- constitute an alternative and independent proof of \textcolor{red}{\texttt{[Theorem 2.1]}}.(i). \\

Given \textcolor{red}{\texttt{Theorem reference}}, it is sufficient to verify (for a fixed $\beta<\beta_c(d,r^*))$, that for each $\sigma\in\Sigma=\set{1,\ldots,s}^{\Z^d}$, there is a unique Gibbs measure for $q$-Potts model with inverse temperature beta on the fibre $\Omega_\sigma=\pi_\r^{-1}(\sigma)$, i.e., that
$$|\G_{\Omega_\sigma}(\Phi_{q,\beta}^\Potts)| ~=~ 1, \quad \forall \sigma\in\Sigma.$$
Luckily, one can express the fibres in a rather nice way, allowing for an easier procedure. Given $\sigma\in\Sigma$, we simply have
$$\Omega_\sigma ~=~ \pi_{\r}^{-1} ~=~ \prod_{i\in\Z^d}\pi_{\r}^{-1}(\sigma_i).$$
Writing $\A_j:=\pi_{\r}^{-1}(j)$ and $U_j:=\set{i\in\Z^d:\pi_{\r}(\sigma_i)=j}$, $j=1,\ldots,s$, we could also write
$$\Omega_\sigma ~=~ \textcolor{purple}{\bigotimes_{j=1}^s\A_j^{U_j}} ~:=~ \prod_{i\in\Z^d}\begin{cases}\A_1:~&i\in U_1,\\
\cdots\\
\A_s:~&i\in U_s.\end{cases}$$
One way of proving the uniqueness of $q$-Potts Gibbs measure on such $\Omega_\sigma$ for \textcolor{blue}{\texttt{an appropriate}} inverse temperature $\beta$, is via the following two steps (so far stated informally):
\begin{itemize}
	\item[(1)] Given the assumption on $\beta$, we know that for each $j=1,\ldots,s$, there is a unique Gibbs measure for Potts model on $\A_j^{\Z^d}$ with inverse temperature $\beta$. We wish to show that this implies also uniqueness of Gibbs measure for Potts model on $\A_j^{U_j}$, given the same inverse temperature.
	\item[(2)] Given the uniqueness of Gibbs measure for Potts model on $\A_j^{U_j}$ with inverse temperature $\beta$ for all $j=1,\ldots,s$, we need to show that this implies the uniqueness of Gibbs measure for Potts model on $\bigotimes_{j=1}^s \A_j^{U_j}$, given the same inverse temperature.
\end{itemize}
\textcolor{blue}{\texttt{Here, I will remark that it is enough to check this for $s=2$, and proceed to restate the above points more formally, in terms of two propositions.}}

% #################################################################################################

\subsection{Preliminaries, part 1: stochastic domination}

In this and the next section, we will introduce some tools, which will be used to prove \textcolor{red}{\texttt{[Proposition reference]}}. The section will cover the basics on stochastic domination, a well-established tool in mathematical statistical mechanics. In the section that follows, we introduce the theory of random cluster representations, which are important in study of the Potts model in particular. 


Assume firstly that $\A\subset\R$ is linearly ordered; in our case, we are generally assuming $\A$ to be finite, though this theory can be extended to closed subsets of $\R$. Then linear order of $\A$ induces a natural (coordinatewise) partial order on $\Omega=\A^\L$: given two configurations $\xi,\xi'\in\Omega$, we write
$$\xi\preceq\xi' ~\iff~ \xi(i)\leq\xi'(i),~\forall i\in\L.$$
This allows us to introduce a notion of increasing functions:

\begin{df}[Increasing functions and events]
~
\begin{itemize}
	\item[(1)] We say that a function $f:\Omega\ra\R$ is \textit{increasing} (or \textit{non-decreasing}), if for each $\xi,\xi'\in\Omega$, $\xi\preceq\xi'$ implies $f(\xi)\leq f(\xi')$. 
	\item[(2)] Equipped with the previous notion, we say that an event $A$ (or a simply $A\subset\Omega$ measurable) is \textit{increasing} if $\1_A$ is an increasing function.
\end{itemize}
\end{df}

\begin{ex}
\textcolor{blue}{\texttt{Percolation probability.}}
\end{ex}

 This allows us to define a certain partial order on $\M_1(\Omega)$, the set of probability measures on $\Omega$. \textcolor{blue}{\texttt{Some comment about motivation for defining stochastic domination/ordering on measures?}}
 
\begin{df}[Stochastic domination]
Let $\mu$ and $\mu'$ be probability measures on $\Omega$. We say that $\mu$ is \textit{stochastically dominated} by $\mu'$, writing $\mu\preceq_\D\mu'$, if
$$\int f\,\d\mu ~\leq~ \int f\,\d\mu', \quad \forall f\in\BM(\Omega,\R).$$
\end{df}

\textcolor{blue}{\texttt{Somethingsomething coupling}}

\begin{df}[Coupling]
Given two probability measures $\mu,\mu'$ on $\Omega$, their \textit{coupling} is defined to be a probability measure $\PP$ on $\Omega\times\Omega$, such that its marginals agree with $\mu$ and $\mu'$, that is
$$\PP(\set{(\xi,\xi'):\xi\in A}) ~=~ \mu(A) \quad \text{and} \quad \PP(\set{(\xi,\xi'):\xi'\in B}) ~=~ \mu'(B).$$
\end{df}

\textcolor{blue}{\texttt{The rest of this section will depend on which argument exactly I will use in the proof, but both Strassen and Holley could be introduced, as a part of a ``general introduction''.}}

% #################################################################################################

\subsection{Preliminaries, part 2: random cluster representations}

% #################################################################################################

\pagebreak

% #################################################################################################
% #################################################################################################
% #################################################################################################

\section{(Non-)Gibbsianity of random spin-flip dynamics}

In this chapter, we introduce the random spin-flip dynamics model, which was explored by van Enter, Fern\'andez, den Hollander and Redig in \textcolor{red}{\texttt{[reference]}}, and proceed to demonstrate, that a special case of this model may be seen as a fuzzy Gibbs model. We present some results about conditions for Gibbsianity and \textcolor{blue}{demonstrate that in the fuzzy Gibbs case, the proofs are analogue to \texttt{our} approach, which in turn verifies, that the example does not contradict the van Enter-Fern\'andez-Sokal hypothesis}.

% #################################################################################################

\subsection{The general model}

We proceed to introduce the model, as defined in \textcolor{red}{\texttt{[reference]}}, with some minor changes in notation. In principle, we are interested in a (probability) measure valued stochastic process $(\nu_t)_{t\geq 0}$, starting from a Gibbs measure. In particular the question the original paper explores is how the conditions on the starting measure and on process-inducing dynamics influence the (non-)Gibbsianity of $\nu_t$, $t>0$. \\

Define first $\Omega_0:=\set{-1,+1}^{\Z^d}$ to be the configuration space. We first consider dynamics on configurations, which is governed by spin-flip rates $\Z^d\times\Omega_0\ni(x,\omega)\mapsto c(x,\omega)$, which satisfy the following conditions:
\begin{itemize}
	\item[(i)] Finite range: for any $x\in\Z^d$, the map $c_x:=(\omega\mapsto c(x,\omega))$ is a local function of $\omega$, with $\mathrm{diam}(\D_{c_x})\leq R<\infty$.
	\item[(ii)] Translation invariance: \textcolor{blue}{for any $x\in\Z^d$, $\tau_x c_0=c_x$}. % define $\tau_x$
	\item[(iii)] Strict positivity: for all $x\in\Z^d$ and $\omega\in\Omega$, $c(x,\omega)>0$.
\end{itemize}

\begin{rem}
It is a direct consequence of assuming (i)-(iii), that there's $m,M\in(0,\infty)$, such that 
$$0 ~<~ m ~\leq~ c(x,\omega) ~\leq~ M ~<~ \infty, \quad \forall x\in\Z^d,\,\omega\in\Omega.$$
\end{rem}

The idea behind the dynamics is as follows: one starts with a (possibly random) configuration $\omega_0$ at time $0$ and flips (random) spins at random times, which are being governed by $(c_x)_{x\in\Z^d}$. That is, site $x\in\Z^d$ is being flipped at \textcolor{blue}{(exponential?)} rate $c_x$, which in general depends on the current configuration, through its value at $x$ and a certain neighbourhood of $x$. Note that unless $\mathrm{diam}(\D_{c_x})=0$ for each $x\in\Z^d$ (i.e., $c(x,\omega)=c(x,\omega(x))$), the flips of individual sites are not independent.\footnote{This scenario, however, will be the one we will focus on later on.} \\

The goal now is to describe a semigroup $(S(t))_{t\geq 0}$ that will describe the dynamics induced by $(c_x)_{x\in\Z^d}$. This motivates us to define a generator $L$ on the space of local functions; writing $\omega^x$ for the configuration that agrees with $\omega$ off $x$ and with $-\omega$ on $x$, we can define
$$Lf ~=~ \sum_{x\in\Z^d}c_x(f(\omega^x)-f(\omega)), \quad f\in\Loc.$$ It is known \textcolor{red}{\texttt{[reference?]}} that the closure of $L$ on $\mathcal{C}(\Omega_0)$ constitutes a generator of a unique Feller process $(\omega_t)_{t\geq 0}$, with $\P_\omega$ the corresponding path-measure, conditional on $\omega_0=\omega$. Furthermore, we obtain the associated semigroup $(S(t))_{t\geq 0}$, which is given by
$$S(t) ~=~ \exp(tL), \quad t\geq 0.$$
It is precisely this semigroup, that in turn also gives us dynamics on measures. To be precise, $(S(t))_{t\geq 0}$ acts on probability measures via	
$$\int_{\Omega_0} [S(t)f](\omega)\,\d\nu(\omega) ~=~ \int_{\Omega_0}f(\omega)\,\d[\nu S(t)](\omega), \quad f\in\Loc,\,\nu\in\M_1(\Omega),\,t\geq 0.$$
In a more explicit language, the measure $\nu S(t)$ assigns a measurable set $A\subset\Omega_0$ a value $[\nu S(t)](A)=\int S(t)\1_A\,\d\nu$. \\

The interpretation turn out to be very intuitive. Letting $\omega_0\in\nu$ be the initial configuration and running the spin-flip dynamics the measure, then
$$\nu S(t) ~=~ \Law(\omega_t), \quad \forall t\geq 0.$$ 

Of central interest is the situation where $\omega_0\sim\mu$, where $\mu$ is a Gibbs measure, that is, $\mu\in\G_{\Omega_0}(\Phi)$ for some translation invariant, finite range \textcolor{blue}{good} interaction $\Phi$. It is also worth noting, that the dynamics induced by $(c_x)_{x\in\Z^d}$ \textcolor{blue}{admits (was this assumption or fact)} a $L$-invariant\footnote{$\int Lf\,\d\rho=0$ for each $f\in\Loc$.} Borel probability measure $\rho$ on $\Omega_0$ which is \textit{reversible}, that is,
$$\int_{\Omega_0}(Lf)g\,\d\rho ~=~ \int_{\Omega_0}f(Lg)\,\d\rho, \quad \forall f,g\in\Loc.$$
Writing $\rho^x$ for the law of $\omega^x$ where $\omega\sim\rho$, the reversibility of $\rho$ for $L$-induced spin flip dynamics is equivalent to
$$\frac{\d\rho^x}{\d\rho} ~=~ \frac{c(x,\omega)}{c(x,\omega^x)}, \quad \forall x\in\Z^d,\,\sigma\in\Omega_0,$$
which implies that there exists a continuous version of Radon-Nikod\'ym derivative $\frac{\d\rho^x}{\d\rho}$. It then follows from Proposition 2.2.~in \textcolor{red}{\texttt{[reference]}} that there exists a \textcolor{blue}{good} interaction $\Psi_\rho$ such that $\rho\in\G_{\Omega_0}(\Psi_\rho)$. Since we assumed $(c_{x})_{x\in\Z^d}$ to have finite range and be translation invariant, we can choose $\Psi_\rho$ to be of finite range and translation invariant as well.\\

The most general result given in the paper is the following:

\begin{thm}
Let $\mu\in\G_{\Omega_0}(\Phi)$ be the law of the original configuration and $\rho\in\Phi(\Psi)$ the reversible measure associated with $(c_x)_{x\in\Z^d}$-dynamics, with $\Phi,\Psi$ finite range \textcolor{blue}{and translation invariant}. Then there exists $t_0=t_0(\mu,\rho)>0$, such that $\mu S(t)$ is Gibbsian for each $0\leq t\leq t_0$. 
\end{thm}

\textcolor{blue}{\texttt{A brief comment.}}
 
% #################################################################################################

\subsection{Infinite-temperature dynamics}

A particularly nice setting, which my much nicer computational prospects is one of ``infinite-temperature'' dynamics, which means simply that spin flips of sites are independent of each other, i.e., the path measure $\P_\omega$ may be expressed as a product measure,
$$\P_\omega ~=~ \bigotimes_{x\in\Z^d}\P_{\omega(x)}.$$
This regime corresponds to $c_x$ depending on configuration only through its values at site $x$, that is, $\mathrm{diam}(\D_{c_x})=0$ for each $x\in\Z^d$. We will see why this model is computationally much simpler in the next section. \\

In this section, we will present some results from \textcolor{red}{\texttt{[reference]}} regarding the Gibbsianity of $(\mu S(t))_{t\geq 0}$ as well as present their proofs, which we will in the next section argue to be \textcolor{blue}{almost analogous} to our approach. \\

Before that, we present a result that is the central tool used in those proofs. If $\mu\in\G_{\Omega_0}(\Phi)$ is the law of the initial configuration, write $\H=(\H_\Lambda)_{\Lambda\Subset\Z^d}$ for the Hamiltonians consistent with $\Phi$. In all the proofs that will be presented, one argues by considering the distributions $\hat{\mu}_t$ of random variables of form $(\omega_0,\omega_t)$, $t\geq 0$. Formally, $\hat{\mu}_t$ enjoys the following correspondence with $\mu$ and $S(t)$:
$$\int_{\Omega_0^2} f(\sigma)g(\eta)\,\d\hat{\mu}_t(\sigma,\eta) ~=~ \int_{\Omega_0}f(\omega)[S(t)g](\omega)\,\d\mu(\omega), \quad f,g\in\Loc.$$
Technically speaking, due to its definition as a joint distribution, $\hat{\mu}_t$ has ``better chances'' of being Gibbsian than $\mu S(t)$. \textcolor{blue}{\texttt{(Elaboration? Any implication?)}} Assuming that it is indeed Gibbsian and writing $(p_t^x)_{t\geq 0}$ for the transition kernel associated with the dynamics at site $x$, the Hamiltonians associated with $\hat{\mu}_t$ may be expressed as
$$\H_\Lambda^{(t)}(\sigma_\Lambda,\eta_\Lambda) ~=~ \H_\Lambda(\sigma_\Lambda) - \sum_{x\in\Lambda}\log p_t^x(\sigma(x),\eta(x)), \quad \sigma,\eta\in\Omega_0.$$
Another assumption that authors make in this section is, that the generators of local spin-sites $(L_x)_{x\in\Z^d}$ are independent of $x$ (i.e., are all the same), and are of form
$$L_x ~=~ \frac{1}{2}\begin{pmatrix}
-1+\varepsilon & 1-\varepsilon \\
1+\varepsilon & -1-\varepsilon
\end{pmatrix}, \quad 0\leq \varepsilon<1,$$
which indeed yields that rates $(p_t^x)_{x\in\Z^d}$ are also independent of $x$, hence all the same.\\

The following result is the first part of the Proposition 3.7.~in \textcolor{red}{\texttt{[reference]}}:
\begin{prop}
Assume that $\hat{\mu}_t$ is indeed Gibbsian. If for each fixed $\eta\in\Omega_0$, there is a unique Gibbs measure associated with the Hamiltonians $(\H_\Lambda^{(t)}(\pika,\eta))_{\Lambda\Subset\Z^d}$ (which one could denote by $|\G_{\Omega_0}(\H^{(t)}(\pika,\eta))|=1$), then $\nu S(t)$ is Gibbsian.
\end{prop}
One can quickly notice a similarity with \textcolor{blue}{\texttt{Berghout's resut}}. \\

\textcolor{blue}{\texttt{Background about Dobrushin's uniqueness condition/high temperature Gibbs measures, if not done before.}}\\

The first result of interest is rather general, as it assumes nothing about the Gibbs measure of the initial configuration, other than its uniqueness w.r.t.~the associated interaction:

\begin{thm}
Let $\mu$ be \textcolor{blue}{either an infinite-~or high-temprature Gibbs measure}, that is, $\mu\in\G_{\Omega_0}(\Phi)$, where $\Phi$ is such that $|\G_{\Omega_0}(\Phi)|=1$. Then, $\mu S(t)$ is Gibbsian for each $t\geq 0$.
\end{thm}

Before stating the proof, we remark that $\H_\Lambda^t$ may be rewritten as
$$\H_\Lambda^{(t)}(\sigma_\Lambda,\eta_\Lambda) ~=~ \H_\Lambda(\sigma_\Lambda) - \sum_{x\in\Lambda}h_1^x(t)\sigma(x) - \sum_{x\in\Lambda}h_2^x(t)\eta(x) - \sum_{x\in\Lambda}h_{1,2}^x(t)\sigma(x)\eta(x), \quad \sigma,\eta\in\Omega_0,$$
where 
\begin{align*}
h_1^x(t) ~&=~ \frac{1}{4}\log\frac{p_t^x(+1,+1)p_t^x(+1,-1)}{p_t^x(-1,+1)p_t^x(-1,-1)}, \\
h_2^x(t) ~&=~ \frac{1}{4}\log\frac{p_t^x(+1,+1)p_t^x(-1,+1)}{p_t^x(+1,-1)p_t^x(-1,-1)} \\
h_{1,2}^x(t) ~&=~ \frac{1}{4}\log\frac{p_t^{x}(+1,+1)p_t^x(-1,-1)}{p_t^x{(+1,-1)}p_t^{x}(-1,+1)}.
\end{align*}
The assumption of independence of $p_t^x$ from $x$, allows us to simply write $h_1,h_2,h_{1,2}$. In fact, the precise expression by which $L_x$ is given also allows us to write those values out nicely, as can be seen in Equation (5.9) in \textcolor{red}{\texttt{[reference]}}, but is for our purposes unimportant.

\begin{proof}
In this case, \textcolor{blue}{we know} the joint distribution $\hat{\mu}_t$ of $(\omega_0,\omega_t)$ to be Gibbsian and consistent with the Hamiltonians $\H^{(t)}$, which can -- due to assumptions of independence of $L_x$ from $x$ -- be written out as
\begin{align*}
\H_\Lambda^{(t)}(\sigma_\Lambda,\eta_\Lambda) ~&=~ \H_\Lambda(\sigma_\Lambda) - \sum_{x\in\Lambda}\oklepaj{h_1(t)+h_{1,2}(t)\eta(x)}\sigma(x) - h_2(t)\sum_{x\in\Lambda}\eta(x).
\end{align*}
We wish to show, that for each fixed $\eta\in\Omega_0$, $|\G_{\Omega_0}(\H^{(t)}(\pika,\eta))|=1$, as the conclusion then follows from \textcolor{red}{\texttt{[reference of Proposition]}}. Indeed, fix arbitrary $\sigma\in\Omega_0$; we immediately notice, that the last term on the RHS is constant in $\sigma$, so we can consider an alternative collection of Hamiltonians $\tilde{\H}^{(t)}(\pika;\eta)$, given by
$$\tilde{\H}_\Lambda^{(t)}(\sigma_\Lambda;\eta) ~=~ \H_\Lambda(\sigma_\Lambda) - \sum_{x\in\Lambda}\oklepaj{h_1(t)+h_{1,2}(t)\eta(x)}\sigma(x),$$
which induces the same specification as $\H^{(t)}(\pika,\eta)$, and hence 
$$\G_{\Omega_0}(\tilde{\H}^{(t)}(\pika;\eta))=\G_{\Omega_0}(\H^{(t)}(\pika,\eta)).$$
\textcolor{blue}{Since $\tilde{\H}^{(t)}(\pika;\eta)$ differs from $\H$ only in the single site interaction, $\tilde{\H}^{(t)}(\pika;\eta)$ satisfies \textcolor{red}{\texttt{[Dobrushin]}} if and only if $\H$ satisfies \textcolor{red}{\texttt{[Dobrushin]}}}. $\H$ indeed satisfies it by assumption, from which it follows that $|\G_{\Omega_0}(\tilde{\H}^{(t)}(\pika;\eta))|=1$ and hence 
$$|\G_{\Omega_0}(\H^{(t)}(\pika,\eta))|=1.$$
As this works for any choice of $\eta$, \textcolor{red}{\texttt{[reference of Proposition]}} allows us to conclude.
\end{proof}

Another example the authors consider is one of the Ising model in the non-uniqueness regime, in particular of $\beta\gg\beta_c$. Here they make an additional assumption on the dynamics, which is that $\varepsilon=0$ in the definition of $L_x$, which translates on neither $+1$ nor $-1$ being favoured, and \textcolor{blue}{results in $h_1\equiv 0$, $h_2\equiv 0$} and $h_{1,2}(t)=:h_t=-\frac{1}{2}\log\tanh(\frac{t}{2})$.

\begin{thm}
Let $\mu_{\beta,h}$ denote some Gibbs measure of Ising model on $\Omega_0$ with $\beta\gg\beta_c$.
\begin{itemize}
	\item[(1)] There exists a $t_0=t_0(\beta,h)$, such that $\nu_{\beta,h}S(t)$ is Gibbsian for all $0\leq t\leq t_0$.
	\item[(2)] Moreover, if $h>0$, then there exists a $t_1=t_1(h)$, such that $\mu_{\beta,h}S(t)$ is Gibbsian for all $t\geq t_1$.
\end{itemize} 
\end{thm}

\begin{proof}
Recalling that the Hamiltonian of the Ising model is of form 
$$\H(\sigma)=-\beta\sum_{(x,y)}\sigma(x)\sigma(y)-h\sum_{x}\sigma(x),$$ 
\textcolor{blue}{slightly ignoring the finite volume and boundary condition business}, we obtain that $\H^{(t)}$ is of form
$$\H^{(t)}(\sigma,\eta) ~=~ -\beta\sum_{(x,y)}\sigma(x)\sigma(y)-h\sum_{x}\sigma(x) - h_t\sum_x \sigma(x)\eta(x).$$
\begin{itemize}
	\item[(1)] We want to exploit the fact that for small $t$, the ``dynamical field'' $h_t$ is large and -- intuitively speaking -- ``forces'' $\sigma$ in ``direction'' of $\eta$. In this spirit, we wish to rewrite the joint Hamiltonian as
\begin{align*}
\H^{(t)}(\sigma,\eta) ~&=~ \sqrt{h_t}\oklepaj{-\frac{\beta}{\sqrt{h_t}}\sum_{(x,y)}\sigma(x)\sigma(y)-\frac{h}{\sqrt{h_t}}\sum_{x}\sigma(x)-\sqrt{h_t}\sum_{x}\sigma(x)\eta(x)} \\
&=:~ \sqrt{h_t}\hat{\H}^{(t)}(\sigma,\eta).
\end{align*}
\textcolor{blue}{It is known from \textcolor{red}{\texttt{reference}}} that for fixed $\eta\in\Omega_0$ and for $0\leq t\leq t_0'$ small enough, $\eta$ is the unique ground state of $\hat{\H}^{(t)}(\pika,\eta)$, so for any $\lambda\geq\lambda_0$ large enough, $\lambda\hat{\H}^{(t)}$ satisfies \textcolor{red}{\texttt{[Dobrushin]}}. It follows that for $0\leq t\leq t_0$ such that $\sqrt{h_t}\geq \lambda_0$, $|\G_{\Omega_0}(\H^{(t)}(\pika,\eta))|$ for all $\eta\in\Omega_0$, allowing us to conclude.
	\item[(2)] We want to exploit the fact that $h_t$ is small for large field and is hence overpowered by $h$; this time around, we write
\begin{align*}
\H^{(t)}(\sigma,\eta) ~&=~ \beta\oklepaj{-\sqrt{\beta}\sum_{(x,y)}\sigma(x)\sigma(y)-\frac{h}{\beta}\sum_{x}\sigma(x)-\frac{h_t}{\sqrt{\beta}}\sum_{x}\sigma(x)\eta(x)} \\
&=:~ \sqrt{\beta}\overline{\H}^{(t)}(\sigma,\eta).
\end{align*}
\textcolor{blue}{For fixed $\eta\in\Omega_0$ and $t>t_1(h)$ large enough, $\frac{h}{|h|}$ is the unique ground state of $\overline{\H}^{(t)}(\pika,\eta)$.} Thus, again by \textcolor{red}{\texttt{[reference]}}, for $\beta$ large enough, $\sqrt{\beta}\overline{\H}^{(t)}(\pika,\eta)$ satisfies \textcolor{red}{\texttt{[Dobrushin]}}. \textcolor{purple}{Why is this enough? Is ``large enough'' independent of $\eta$? Or is there a uniform bound?}
\end{itemize}
\end{proof}

\begin{rem}
The same result can be obtained for $\varepsilon>0$, though in that case $t_i$'s also depend on $\delta=\frac{1-\varepsilon}{1+\varepsilon}$.
\end{rem}

% #################################################################################################

\subsection{Alternative approach: dynamics as a fuzzy map}

\textcolor{blue}{In the previous section, we have remarked on the similarity between \textcolor{red}{\texttt{[Proposition]}} and \textcolor{red}{\texttt{Berghout's result}}.} The aim of this section is firstly to argue that one can view the dynamics described in the previous section as a fuzzy model, and secondly to demonstrate that the proofs of those same results are very similar, despite the alternative approach. \\

Recall again that we assumed that the dynamics are i.i.d.\footnote{This is concluded by combining the assumption that $\P_\omega=\bigotimes_{x\in\Z^d}\P_{\omega(x)}$ and the assumption that $(L_x)_{x\in\Z^d}$ are independent of $x$.}, with no bias towards either $+1$ or $-1$ spins ($\varepsilon=0$). Considering the spin flip rates $c(x,\omega)$, the first assumption removes the dependence on the first coordinate and restricts the dependence in the second coordinate to only $\omega(x)$, while the second assumptions fully removes the dependence on the second coordinate. This yields that the dynamics are given by a collection of independent \textcolor{blue}{Poisson clocks} with rate $c>0$. \\

It is thus rather simple to describe probabilities of a certain value being assumed at a specific spin at any given time. Indeed, on has that, for $x\in\Z^d$ and $t>0$,
\begin{align*}
[\mu S(t)](\omega_t(x)=1) ~=~ \mu(\omega_0(x)=1)\P(\text{even flips of}~x) + \mu(\omega_0(x)=-1)\P(\text{odd flips of}~x),
\end{align*}
where $\P(\text{odd flips of}~x)$ of course corresponds to the probability of there being even number of arrivals of Poisson process with intensity $c$ until time $t$. Famously, the latter carries the probability of $\frac{1}{2}(1-e^{-2tc})$, yielding
$$[\mu S(t)](\omega_t(x)=1) ~=~ \mu(\omega_0(x)=1)\frac{1+e^{-2tc}}{2} + \mu(\omega_0(x)=-1)\frac{1-e^{-2tc}}{2}.$$

The assumptions of this particular model allow us to consider the alternative to considering the joint distribution of $(\omega_0,\omega_t)$, as was done before. In particular, we will rather focus on the joint distribution of $\omega_0$ and dynamics (that is, whether there was odd or even number of spins at any site) until time $t$. The advantage of this approach is, that while $\omega_t$ does indeed depend on $\omega_0$ (and their joint distribution is not necessarily Gibbsian), the information about the dynamics up until $t$ \textit{is} -- due to no bias via $\varepsilon=0$ -- independent of $\omega_0$. The joint distribution is thus a product measure and \textcolor{purple}{hence automatically Gibbsian on $\Omega_0^2$.} Moreover, it is also easy to see that such construction allows us to see each $\mu S(t)$ as a fuzzy Gibbs measure, allowing us to use tools from \textcolor{red}{\texttt{[first chapter]}}.

% #################################################################################################

\end{document}